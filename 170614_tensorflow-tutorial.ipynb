{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [tensorflow](https://www.tensorflow.org)の紹介\n",
    "\n",
    "*170614 Masahiro Rikiso*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは[これ](https://www.tensorflow.org/get_started/mnist/beginners) だけ読んでればOK\n",
    "\n",
    "* [1. データの読み込み](#1.-データの読み込み)\n",
    "* [2. 学習用データの作成](#2.-学習用データの作成)\n",
    "* [3. 機械学習モデルの作成](#3.-機械学習モデルの作成)\n",
    "* [4. モデルの評価](#4.-モデルの評価)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データの読み込み\n",
    "\n",
    "下の2行で読み込める。覚える必要なし。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学習用データの作成\n",
    "\n",
    "tensorflowAPIで読み込んで時点で、train-validation-test-splitが自動的にされてます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.tensorflow.org/images/mnist-train-xs.png\" width=300>\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/mnist-train-ys.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 784), (5000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = mnist.validation.images\n",
    "y_val = mnist.validation.labels\n",
    "\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUIQfCOq/esVX4lsZQ0YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111b8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_sample = X_train[0].reshape(28,28)\n",
    "plt.imshow(img_sample, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 機械学習モデルの作成\n",
    "\n",
    "隠れ層 2層のDNNを組んでみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# パラメータ（ほんとは試行錯誤で決める）\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# こっちはデータセットで自動的に決まるパラメータ\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.placeholder`: 入力、出力など「定数のいれもの」を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.Variable`: 重みやバイアスなど「変数のいれもの」を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2層ニューラルネットを定義します。\n",
    "\n",
    "Input(784) -- FC(256, ReLU) -- FC(256, ReLU) -- Output(10, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 目的関数: cross_entropy\n",
    "* 最適化手法: adam\n",
    "\n",
    "を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初期化メソッドを定義（tensorflowのおまじないみたいなもん。あんま気にしなくていい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここから、実際の学習コード。\n",
    "\n",
    "`with tf.Session() as sess:` でくくって、\n",
    "\n",
    "その中で\n",
    "\n",
    "1. 初期化: `sess.run(init)`\n",
    "2. 学習: `sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})`\n",
    "\n",
    "する。 2. 学習のところは forループで何回も回す。\n",
    "\n",
    "仕組みは、sess.run(arg)と書くと、argを得るのに必要な計算が実行されて、返り値として計算されたargが返る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss(cross_entropy)= 188.736816755\n",
      "Epoch: 0002 loss(cross_entropy)= 48.096417374\n",
      "Epoch: 0003 loss(cross_entropy)= 30.611777298\n",
      "Epoch: 0004 loss(cross_entropy)= 21.902288404\n",
      "Epoch: 0005 loss(cross_entropy)= 16.086965740\n",
      "Epoch: 0006 loss(cross_entropy)= 12.228513490\n",
      "Epoch: 0007 loss(cross_entropy)= 9.621035945\n",
      "Epoch: 0008 loss(cross_entropy)= 7.439101037\n",
      "Epoch: 0009 loss(cross_entropy)= 5.807910895\n",
      "Epoch: 0010 loss(cross_entropy)= 4.431958169\n",
      "Epoch: 0011 loss(cross_entropy)= 3.434407504\n",
      "Epoch: 0012 loss(cross_entropy)= 2.748598935\n",
      "Epoch: 0013 loss(cross_entropy)= 2.123592254\n",
      "Epoch: 0014 loss(cross_entropy)= 1.614521905\n",
      "Epoch: 0015 loss(cross_entropy)= 1.288336359\n",
      "Optimization Finished!\n",
      "Accuracy(Test Dataset): 0.9409\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"loss(cross_entropy)=\", \\\n",
    "                \"{:.9f}\".format(avg_cost)\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print \"Accuracy(Test Dataset):\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">参考リソース: http://nbviewer.jupyter.org/github/aymericdamien/TensorFlow-Examples/tree/master/notebooks/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
